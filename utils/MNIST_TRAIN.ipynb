{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YU-JVjkaoZL0"
      },
      "outputs": [],
      "source": [
        "# Import dependencies\n",
        "\n",
        "import torch\n",
        "from torch import nn, save\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import ConcatDataset\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# %matplotlib widget\n",
        "# %load_ext tensorboard\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7DFdRi0B5_4",
        "outputId": "ca58b55e-93fa-40d3-8d4a-8dc91aecefc2"
      },
      "outputs": [],
      "source": [
        "# Get data\n",
        "original_ds = datasets.MNIST(root=\"data\", download=True, train=True, transform=ToTensor())\n",
        "print(f\"Dataset size: {len(original_ds)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JF-1JeNiF2JE",
        "outputId": "2e425218-449b-4b2a-cb19-b7bccda9147e"
      },
      "outputs": [],
      "source": [
        "# print number of images in each class\n",
        "labels = [y for _, y in original_ds]\n",
        "unique, counts = np.unique(labels, return_counts=True)\n",
        "for i in range(len(unique)):\n",
        "    print(f\"Number of {unique[i]}s: {counts[i]}\")\n",
        "print(\"----------------------------------\")\n",
        "print(f\"Total number of images: {sum(counts)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECKZIngcosS_"
      },
      "outputs": [],
      "source": [
        "# make 4000 new images for each class using augmentation\n",
        "\n",
        "\n",
        "# Define the augmentation transformations\n",
        "augmentation_transform = transforms.Compose([\n",
        "    transforms.RandomAffine(degrees=25, translate=(0.2, 0.2), scale=(0.8, 1.2)),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
        "\n",
        "])\n",
        "\n",
        "\n",
        "# Function to create augmented dataset for a specific class\n",
        "def create_augmented_dataset(original_dataset, class_label, num_augmented_images, augmentation_transform):\n",
        "    class_indices = [i for i, (image, label) in enumerate(original_dataset) if label == class_label]\n",
        "    selected_indices = np.random.choice(class_indices, num_augmented_images, replace=False)\n",
        "\n",
        "    augmented_dataset = datasets.MNIST(\n",
        "        root=\"data\",\n",
        "        train=True,\n",
        "        transform=transforms.Compose([\n",
        "            transforms.Lambda(lambda x: augmentation_transform(x)),\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "    )\n",
        "\n",
        "    augmented_dataset.data = [original_dataset.data[idx] for idx in selected_indices]\n",
        "    augmented_dataset.targets = [original_dataset.targets[idx] for idx in selected_indices]\n",
        "\n",
        "    return augmented_dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RATOZ0RdF2JF",
        "outputId": "232b4078-d6b0-430a-aa1b-835da30189da"
      },
      "outputs": [],
      "source": [
        "# Create augmented datasets for each class\n",
        "num_augmented_images_per_class = 4000\n",
        "augmented_ds = []\n",
        "\n",
        "for class_label in range(10):\n",
        "    augmented_dataset = create_augmented_dataset(original_ds, class_label, num_augmented_images_per_class, augmentation_transform)\n",
        "    augmented_ds.append(augmented_dataset)\n",
        "\n",
        "# Concatenate the original dataset with augmented datasets\n",
        "combined_ds = ConcatDataset([original_ds] + augmented_ds)\n",
        "\n",
        "\n",
        "# Print the size of the combined dataset\n",
        "print(f\"Combined Dataset size: {len(combined_ds)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27oNoBfaF2JG"
      },
      "outputs": [],
      "source": [
        "# Convert the dataset targets to a NumPy array for faster indexing\n",
        "targets_np = np.array([label for _, label in combined_ds])\n",
        "\n",
        "# Create a dictionary to store indices for each class\n",
        "class_indices_dict = {class_label: np.where(targets_np == class_label)[0].tolist() for class_label in range(10)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "id": "NHmOaBwyF2JG",
        "outputId": "4406596e-ad84-4951-8253-22700e32c41e"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define a function to show images\n",
        "def show_images(images, ncols=5):\n",
        "    fig, axes = plt.subplots(nrows=1, ncols=ncols, figsize=(10, 10))\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        ax.imshow(images[i].squeeze(), cmap=\"gray\")\n",
        "        ax.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "# Iterate through each class and show 5 augmented_ds images\n",
        "for class_label in range(10):\n",
        "    num_of_imgs = 10\n",
        "    selected_indices = np.random.choice(class_indices_dict[class_label], num_of_imgs, replace=False)\n",
        "    images = [combined_ds[idx][0] for idx in selected_indices]\n",
        "    labels = [combined_ds[idx][1] for idx in selected_indices]\n",
        "    show_images(images, ncols=num_of_imgs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmBAqlaAobu6",
        "outputId": "5053ca16-5bd1-4cc3-8959-a5731fbbe556"
      },
      "outputs": [],
      "source": [
        "print(f\"combined dataset size: {len(combined_ds)}\")\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "train_size = int(0.8 * len(combined_ds))  # Use 80% of the data for training\n",
        "test_size = len(combined_ds) - train_size\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(combined_ds, [train_size, test_size])\n",
        "\n",
        "print(f\"Train dataset size: {len(train_dataset)}\")\n",
        "print(f\"Test dataset size: {len(test_dataset)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpRiZHF5oc-r"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Create data loaders for training and testing\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qM0obFdynb4D"
      },
      "outputs": [],
      "source": [
        "# Image Classifier Neural Network\n",
        "class ImageClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImageClassifier, self).__init__()\n",
        "\n",
        "        # First convolutional layer\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)  # Batch normalization for conv1\n",
        "        self.relu1 = nn.ReLU()  # ReLU activation after conv1\n",
        "\n",
        "        # Second convolutional layer\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)  # Batch normalization for conv2\n",
        "        self.relu2 = nn.ReLU()  # ReLU activation after conv2\n",
        "\n",
        "        # Third convolutional layer\n",
        "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(64)  # Batch normalization for conv3\n",
        "        self.relu3 = nn.ReLU()  # ReLU activation after conv3\n",
        "\n",
        "        # Flatten layer to transition from convolutions to fully connected layers\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        # First fully connected layer\n",
        "        self.fc1 = nn.Linear(64 * 28 * 28, 128)  # 64 channels, 28x28 image size -> 128 units\n",
        "        self.dropout = nn.Dropout(0.5)  # Dropout layer with 50% dropout probability\n",
        "\n",
        "        # Final output layer\n",
        "        self.fc2 = nn.Linear(128, 10)  # 128 units to 10 classes (for MNIST digits)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Layer operations in forward pass\n",
        "        x = self.relu1(self.bn1(self.conv1(x)))  # conv1 -> batch norm -> ReLU\n",
        "        x = self.relu2(self.bn2(self.conv2(x)))  # conv2 -> batch norm -> ReLU\n",
        "        x = self.relu3(self.bn3(self.conv3(x)))  # conv3 -> batch norm -> ReLU\n",
        "        x = self.flatten(x)  # Flatten the output for fully connected layers\n",
        "        x = self.dropout(self.relu1(self.fc1(x)))  # Fully connected -> ReLU -> Dropout\n",
        "        x = self.fc2(x)  # Final output layer\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7U9CVgnQo1of"
      },
      "outputs": [],
      "source": [
        "# Instance of the neural network, loss, optimizer\n",
        "clf = ImageClassifier().to('cuda')\n",
        "opt = Adam(clf.parameters(), lr=1e-3)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVVaiXVWo521",
        "outputId": "10a32a8c-fb54-422d-fd25-14404ebafa23"
      },
      "outputs": [],
      "source": [
        "# Training loop\n",
        "step = 0\n",
        "epochs_num = 10\n",
        "epoch_loss = []\n",
        "epoch_accuracies = []\n",
        "for epoch in range(epochs_num):\n",
        "    losses = []\n",
        "    accuracies = []\n",
        "    for idx, batch in enumerate(train_loader):\n",
        "        # Get data\n",
        "        X, y = batch\n",
        "        # Move data to GPU\n",
        "        X, y = X.to('cuda'), y.to('cuda')\n",
        "        # Get prediction\n",
        "        yhat = clf(X)\n",
        "        # Calculate loss\n",
        "        loss = loss_fn(yhat, y)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        # Apply backpropagation\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        _, predicted = torch.max(yhat, 1)\n",
        "        accuracy = (predicted == y).float().mean().item()\n",
        "        accuracies.append(accuracy)\n",
        "\n",
        "        step += 1\n",
        "\n",
        "\n",
        "    avg_loss = sum(losses) / len(losses)\n",
        "    avg_accuracy = sum(accuracies) / len(accuracies)\n",
        "    epoch_loss.append(avg_loss)\n",
        "    epoch_accuracies.append(avg_accuracy)\n",
        "    print(f\"Epoch: {epoch} | Loss: {avg_loss:.5f} | Accuracy: {avg_accuracy:.5f}\")\n",
        "\n",
        "\n",
        "\n",
        "# save the model\n",
        "with open('model_state.pt', 'wb') as f:\n",
        "    save(clf.state_dict(), f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aEJMxLJo8Wm",
        "outputId": "a1f01f82-f20a-4a07-b0d2-1ed7c15da5d0"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on the test set\n",
        "clf.eval()  # Set the model to evaluation mode\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to('cuda'), labels.to('cuda')\n",
        "        outputs = clf(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f\"Accuracy on the testset: {accuracy * 100:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
